{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6911938,"sourceType":"datasetVersion","datasetId":3969526},{"sourceId":6982707,"sourceType":"datasetVersion","datasetId":4013008},{"sourceId":6999806,"sourceType":"datasetVersion","datasetId":4023863}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#IMPORTING THE LIBRARIES.\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:25:42.447584Z","iopub.execute_input":"2023-11-19T04:25:42.448412Z","iopub.status.idle":"2023-11-19T04:25:42.894638Z","shell.execute_reply.started":"2023-11-19T04:25:42.448365Z","shell.execute_reply":"2023-11-19T04:25:42.893565Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install librosa","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:25:47.484350Z","iopub.execute_input":"2023-11-19T04:25:47.484881Z","iopub.status.idle":"2023-11-19T04:26:02.951584Z","shell.execute_reply.started":"2023-11-19T04:25:47.484848Z","shell.execute_reply":"2023-11-19T04:26:02.950506Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.1)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.1)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.24.3)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.11.3)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.3.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.57.1)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.12.1)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.8.0)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3.7)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.5.0)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.0.5)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.40.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa) (4.0.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa) (21.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa) (2.31.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pooch>=1.0->librosa) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"code","source":"import librosa","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:26:02.953840Z","iopub.execute_input":"2023-11-19T04:26:02.954213Z","iopub.status.idle":"2023-11-19T04:26:02.966290Z","shell.execute_reply.started":"2023-11-19T04:26:02.954179Z","shell.execute_reply":"2023-11-19T04:26:02.965040Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"parent_directory=\"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand\"\nfolder_list=os.listdir(parent_directory)\nfolder_list.remove('_background_noise_')  # Removes the backgroundnoise folder\nprint(folder_list)\nprint(len(folder_list))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:26:02.967744Z","iopub.execute_input":"2023-11-19T04:26:02.968200Z","iopub.status.idle":"2023-11-19T04:26:02.990623Z","shell.execute_reply.started":"2023-11-19T04:26:02.968167Z","shell.execute_reply":"2023-11-19T04:26:02.989853Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['no', 'two', 'four', 'five', 'nine', 'right', 'off', 'yes', 'six', 'dog', 'left', 'bird', 'wow', 'zero', 'eight', 'bed', 'go', 'house', 'tree', 'seven', 'on', 'three', 'one', 'down', 'stop', 'up', 'happy', 'marvin', 'cat', 'sheila']\n30\n","output_type":"stream"}]},{"cell_type":"code","source":"values=[8,21,29,27,10,0,28,25,24,7,11,16,9,17,1,4,6,22,3,18,26,13,15,23,12,19,5,20,2,14]\nlen(values)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:26:02.992167Z","iopub.execute_input":"2023-11-19T04:26:02.992468Z","iopub.status.idle":"2023-11-19T04:26:03.003244Z","shell.execute_reply.started":"2023-11-19T04:26:02.992432Z","shell.execute_reply":"2023-11-19T04:26:03.002081Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"30"},"metadata":{}}]},{"cell_type":"code","source":"class_mapping=dict(zip(folder_list,values))\nclass_mapping","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:26:03.004646Z","iopub.execute_input":"2023-11-19T04:26:03.005023Z","iopub.status.idle":"2023-11-19T04:26:03.018542Z","shell.execute_reply.started":"2023-11-19T04:26:03.004983Z","shell.execute_reply":"2023-11-19T04:26:03.017386Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'no': 8,\n 'two': 21,\n 'four': 29,\n 'five': 27,\n 'nine': 10,\n 'right': 0,\n 'off': 28,\n 'yes': 25,\n 'six': 24,\n 'dog': 7,\n 'left': 11,\n 'bird': 16,\n 'wow': 9,\n 'zero': 17,\n 'eight': 1,\n 'bed': 4,\n 'go': 6,\n 'house': 22,\n 'tree': 3,\n 'seven': 18,\n 'on': 26,\n 'three': 13,\n 'one': 15,\n 'down': 23,\n 'stop': 12,\n 'up': 19,\n 'happy': 5,\n 'marvin': 20,\n 'cat': 2,\n 'sheila': 14}"},"metadata":{}}]},{"cell_type":"markdown","source":"## APPROACH 1","metadata":{}},{"cell_type":"code","source":"#Learning about the mfccs coefficient.\n\n# Step 2: Load the Audio File\naudio_file = \"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand/bed/00176480_nohash_0.wav\"  # Replace with the path to your audio file\naudio_data, sample_rate = librosa.load(audio_file, sr=None)  # Use sr=None to preserve the native sample rate\n\n# Step 3: Segment the Audio\nframe_length = int(sample_rate * 0.025)  # Frame length (25 ms)\nhop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\nframes = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n# Step 4: MFCC Calculation\nn_mfcc = 13  # Number of MFCC coefficients\nmfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.375672Z","iopub.execute_input":"2023-11-16T08:34:42.376284Z","iopub.status.idle":"2023-11-16T08:34:42.415034Z","shell.execute_reply.started":"2023-11-16T08:34:42.376236Z","shell.execute_reply":"2023-11-16T08:34:42.413320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mfccs)\nprint(mfccs.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.418350Z","iopub.execute_input":"2023-11-16T08:34:42.419655Z","iopub.status.idle":"2023-11-16T08:34:42.431399Z","shell.execute_reply.started":"2023-11-16T08:34:42.419591Z","shell.execute_reply":"2023-11-16T08:34:42.429874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Learning about the mfccs coefficient.\n\n# Step 2: Load the Audio File\naudio_file = \"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand/bed/0135f3f2_nohash_0.wav\"  # Replace with the path to your audio file\naudio_data, sample_rate = librosa.load(audio_file, sr=None)  # Use sr=None to preserve the native sample rate\n\n# Step 3: Segment the Audio\nframe_length = int(sample_rate * 0.025)  # Frame length (25 ms)\nhop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\nframes = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n# Step 4: MFCC Calculation\nn_mfcc = 13  # Number of MFCC coefficients\nmfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.434683Z","iopub.execute_input":"2023-11-16T08:34:42.436075Z","iopub.status.idle":"2023-11-16T08:34:42.475618Z","shell.execute_reply.started":"2023-11-16T08:34:42.435985Z","shell.execute_reply":"2023-11-16T08:34:42.474006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mfccs)\nprint(mfccs.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.484534Z","iopub.execute_input":"2023-11-16T08:34:42.488977Z","iopub.status.idle":"2023-11-16T08:34:42.505473Z","shell.execute_reply.started":"2023-11-16T08:34:42.488900Z","shell.execute_reply":"2023-11-16T08:34:42.504440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Specify the directory path containing the audio files\n# audio_directory = \"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand/bed\"\n\n# # Define a maximum length for your MFCCs (adjust as needed)\n# max_mfcc_length = 101 # For example, you can set this to the maximum expected length\n\n# # Initialize empty lists to store the extracted MFCCs and their corresponding labels (if available)\n# mfccs_list = []\n# labels = []\n\n# # Iterate through audio files in the directory\n# for filename in os.listdir(audio_directory):\n#     if filename.endswith(\".wav\"):  # Assuming the audio files are in WAV format\n#         file_path = os.path.join(audio_directory, filename)\n\n#         # Load the audio file and extract MFCCs\n#         audio_data, sample_rate = librosa.load(file_path, sr=None)\n#         mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n\n#         # Pad or truncate the MFCCs to a common length\n#         if mfccs.shape[1] < max_mfcc_length:\n#             # Pad the MFCCs with zeros to reach the desired length\n#             mfccs = np.pad(mfccs, ((0, 0), (0, max_mfcc_length - mfccs.shape[1])), mode='constant')\n#         else:\n#             # Truncate the MFCCs to the desired length\n#             mfccs = mfccs[:, :max_mfcc_length]\n\n#         # Append the extracted MFCCs to the list\n#         mfccs_list.append(mfccs)\n#         labels.append(4)\n\n#         # If you have class labels, you can load them and associate them with the MFCCs\n#         # labels.append(class_label)  # Replace 'class_label' with your actual label\n\n# # Convert the list of MFCCs to a NumPy array for further processing\n# mfccs_array = np.array(mfccs_list)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.512900Z","iopub.execute_input":"2023-11-16T08:34:42.518127Z","iopub.status.idle":"2023-11-16T08:34:42.532266Z","shell.execute_reply.started":"2023-11-16T08:34:42.518037Z","shell.execute_reply":"2023-11-16T08:34:42.530662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mfccs_array.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.538369Z","iopub.execute_input":"2023-11-16T08:34:42.542616Z","iopub.status.idle":"2023-11-16T08:34:42.557947Z","shell.execute_reply.started":"2023-11-16T08:34:42.542540Z","shell.execute_reply":"2023-11-16T08:34:42.556172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.575646Z","iopub.execute_input":"2023-11-16T08:34:42.580134Z","iopub.status.idle":"2023-11-16T08:34:42.590188Z","shell.execute_reply.started":"2023-11-16T08:34:42.580058Z","shell.execute_reply":"2023-11-16T08:34:42.588588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #PARENT LIST\n# class_mfcc_list=[]\n# class_label_list=[]\n\n# #LIST FOR EACH CLASS\n# mfccs_list = []\n# labels = []\n# max_mfcc_length = 101\n\n# parent_directory=\"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand\"\n\n# for i,j in class_mapping.items():\n#     class_directory=os.path.join(parent_directory,i)\n#     # Iterate through audio files in the directory\n#     mfccs_list = []\n#     labels = []\n#     for filename in os.listdir(class_directory):\n#         if filename.endswith(\".wav\"):  # Assuming the audio files are in WAV format\n#             file_path = os.path.join(class_directory, filename)\n\n#         # Load the audio file and extract MFCCs\n#         audio_data, sample_rate = librosa.load(file_path, sr=None)\n#         mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n\n#         # Pad or truncate the MFCCs to a common length\n#         if mfccs.shape[1] < max_mfcc_length:\n#             # Pad the MFCCs with zeros to reach the desired length\n#             mfccs = np.pad(mfccs, ((0, 0), (0, max_mfcc_length - mfccs.shape[1])), mode='constant')\n#         else:\n#             # Truncate the MFCCs to the desired length\n#             mfccs = mfccs[:, :max_mfcc_length]\n\n#         # Append the extracted MFCCs to the list\n#         mfccs_list.append(mfccs)\n#         labels.append(j)\n    \n#     mfccs_array = np.array(mfccs_list)\n#     class_mfcc_list.append(mfccs_array)\n#     class_label_list.append(labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.593147Z","iopub.execute_input":"2023-11-16T08:34:42.594148Z","iopub.status.idle":"2023-11-16T08:34:42.604118Z","shell.execute_reply.started":"2023-11-16T08:34:42.594103Z","shell.execute_reply":"2023-11-16T08:34:42.602535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(class_mfcc_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.605666Z","iopub.execute_input":"2023-11-16T08:34:42.606422Z","iopub.status.idle":"2023-11-16T08:34:42.622061Z","shell.execute_reply.started":"2023-11-16T08:34:42.606384Z","shell.execute_reply":"2023-11-16T08:34:42.620374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_mapping","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.624006Z","iopub.execute_input":"2023-11-16T08:34:42.625316Z","iopub.status.idle":"2023-11-16T08:34:42.634733Z","shell.execute_reply.started":"2023-11-16T08:34:42.625277Z","shell.execute_reply":"2023-11-16T08:34:42.633148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_mfcc_list[15].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.636864Z","iopub.execute_input":"2023-11-16T08:34:42.638124Z","iopub.status.idle":"2023-11-16T08:34:42.647995Z","shell.execute_reply.started":"2023-11-16T08:34:42.638077Z","shell.execute_reply":"2023-11-16T08:34:42.646591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_mfcc_list[15]","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.649745Z","iopub.execute_input":"2023-11-16T08:34:42.651069Z","iopub.status.idle":"2023-11-16T08:34:42.660613Z","shell.execute_reply.started":"2023-11-16T08:34:42.651008Z","shell.execute_reply":"2023-11-16T08:34:42.659220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(class_label_list[15])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.662265Z","iopub.execute_input":"2023-11-16T08:34:42.663548Z","iopub.status.idle":"2023-11-16T08:34:42.673783Z","shell.execute_reply.started":"2023-11-16T08:34:42.663505Z","shell.execute_reply":"2023-11-16T08:34:42.672080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #RESHAPING THE DATA WE HAVE EXTRACTED.\n\n# # Assuming your data is 'folder_data' with shape (2100, 13, 101)\n# n_samples, n_mfcc, n_frames = class_mfcc_list[0].shape\n\n# # # Reshape the data to have 2100 rows and (13 * 101) columns\n# reshaped_data = class_mfcc_list[0].reshape((n_samples, n_mfcc * n_frames))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.675966Z","iopub.execute_input":"2023-11-16T08:34:42.677448Z","iopub.status.idle":"2023-11-16T08:34:42.685760Z","shell.execute_reply.started":"2023-11-16T08:34:42.677399Z","shell.execute_reply":"2023-11-16T08:34:42.684796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshaped_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.687406Z","iopub.execute_input":"2023-11-16T08:34:42.688814Z","iopub.status.idle":"2023-11-16T08:34:42.698754Z","shell.execute_reply.started":"2023-11-16T08:34:42.688769Z","shell.execute_reply":"2023-11-16T08:34:42.697617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshaped_data","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.700399Z","iopub.execute_input":"2023-11-16T08:34:42.702094Z","iopub.status.idle":"2023-11-16T08:34:42.711573Z","shell.execute_reply.started":"2023-11-16T08:34:42.702021Z","shell.execute_reply":"2023-11-16T08:34:42.710371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.mixture import GaussianMixture\n# class_gmms={}\n\n# # Iterate through the class features and labels\n# for class_features, class_label in zip(class_mfcc_list, class_label_list):\n#     # Convert class_label to an integer if it's not already\n#     class_label = int(class_label[0])\n    \n#     # Reshape the class features to 2D (n_samples, n_mfcc_coefficients * n_frames)\n#     n_samples, n_mfcc, n_frames = class_features.shape\n#     reshaped_features = class_features.reshape((n_samples, n_mfcc * n_frames))\n\n#     # Initialize and train a GMM model for the current class\n#     gmm = GaussianMixture(n_components=3, covariance_type='diag', random_state=42)\n#     gmm.fit(reshaped_features)\n\n#     # Store the GMM model in the dictionary with the class label as the key\n#     class_gmms[class_label] = gmm\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.713714Z","iopub.execute_input":"2023-11-16T08:34:42.714544Z","iopub.status.idle":"2023-11-16T08:34:42.724899Z","shell.execute_reply.started":"2023-11-16T08:34:42.714507Z","shell.execute_reply":"2023-11-16T08:34:42.723497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test Data","metadata":{}},{"cell_type":"code","source":"# #Learning about the mfccs coefficient.\n\n# # Step 2: Load the Audio File\n# audio_file = \"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommandTest/A_1000563aa4e6_nohash_1.wav\"  # Replace with the path to your audio file\n# audio_data, sample_rate = librosa.load(audio_file, sr=None)  # Use sr=None to preserve the native sample rate\n\n# # Step 3: Segment the Audio\n# frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n# hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n# frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n# # Step 4: MFCC Calculation\n# n_mfcc = 13  # Number of MFCC coefficients\n# mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.726432Z","iopub.execute_input":"2023-11-16T08:34:42.726982Z","iopub.status.idle":"2023-11-16T08:34:42.741776Z","shell.execute_reply.started":"2023-11-16T08:34:42.726950Z","shell.execute_reply":"2023-11-16T08:34:42.740758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mfccs.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.743112Z","iopub.execute_input":"2023-11-16T08:34:42.743915Z","iopub.status.idle":"2023-11-16T08:34:42.755677Z","shell.execute_reply.started":"2023-11-16T08:34:42.743881Z","shell.execute_reply":"2023-11-16T08:34:42.754166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# type(mfccs)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.757478Z","iopub.execute_input":"2023-11-16T08:34:42.757852Z","iopub.status.idle":"2023-11-16T08:34:42.767564Z","shell.execute_reply.started":"2023-11-16T08:34:42.757823Z","shell.execute_reply":"2023-11-16T08:34:42.766137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #RESHAPING THE DATA WE HAVE EXTRACTED.\n\n# # Assuming your data is 'folder_data' with shape (2100, 13, 101)\n# n_mfcc, n_frames = mfccs.shape\n\n# # # Reshape the data to have 2100 rows and (13 * 101) columns\n# reshaped_data = mfccs.reshape(n_mfcc * n_frames)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.769813Z","iopub.execute_input":"2023-11-16T08:34:42.770653Z","iopub.status.idle":"2023-11-16T08:34:42.780247Z","shell.execute_reply.started":"2023-11-16T08:34:42.770608Z","shell.execute_reply":"2023-11-16T08:34:42.778787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshaped_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.781885Z","iopub.execute_input":"2023-11-16T08:34:42.782923Z","iopub.status.idle":"2023-11-16T08:34:42.792669Z","shell.execute_reply.started":"2023-11-16T08:34:42.782874Z","shell.execute_reply":"2023-11-16T08:34:42.791122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Assuming you have a single test audio sample as 'test_audio_features'\n\n# # Calculate likelihoods for each class using the GMM models\n# likelihoods = {}\n# for class_label, gmm_model in class_gmms.items():\n#     likelihood = gmm_model.score_samples(reshaped_data.reshape(1, -1))\n#     likelihoods[class_label] = likelihood\n\n# # Find the class label with the highest likelihood\n# predicted_label = max(likelihoods, key=likelihoods.get)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.795153Z","iopub.execute_input":"2023-11-16T08:34:42.795623Z","iopub.status.idle":"2023-11-16T08:34:42.805070Z","shell.execute_reply.started":"2023-11-16T08:34:42.795583Z","shell.execute_reply":"2023-11-16T08:34:42.804085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicted_label","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:34:42.806706Z","iopub.execute_input":"2023-11-16T08:34:42.807961Z","iopub.status.idle":"2023-11-16T08:34:42.821703Z","shell.execute_reply.started":"2023-11-16T08:34:42.807909Z","shell.execute_reply":"2023-11-16T08:34:42.820119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## APPROACH 2","metadata":{}},{"cell_type":"code","source":"folder_list","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:41:25.230474Z","iopub.execute_input":"2023-11-16T13:41:25.230977Z","iopub.status.idle":"2023-11-16T13:41:25.240604Z","shell.execute_reply.started":"2023-11-16T13:41:25.230917Z","shell.execute_reply":"2023-11-16T13:41:25.239088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"background_noise=os.listdir('/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand/_background_noise_')\nbackground_noise","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:41:28.483506Z","iopub.execute_input":"2023-11-16T13:41:28.485025Z","iopub.status.idle":"2023-11-16T13:41:28.503515Z","shell.execute_reply.started":"2023-11-16T13:41:28.484920Z","shell.execute_reply":"2023-11-16T13:41:28.502415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing for one audio file\n# Load audio file (replace 'your_audio_file.wav' with the actual file path)\naudio_data, sample_rate = librosa.load('/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand/bed/00176480_nohash_0.wav', sr=None)\n\n# Extract MFCCs with a larger hop_length to increase the number of frames\nmfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13, hop_length=256)\n\n# Extract Delta and Delta-Delta Coefficients\ndelta = librosa.feature.delta(mfccs)\ndelta_delta = librosa.feature.delta(mfccs, order=2)\n\n# Combine features into a single feature matrix,stacking horizontally\nfeatures = np.hstack([mfccs, delta, delta_delta])\nflat_mfcc = features.reshape(1, -1)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:41:32.125249Z","iopub.execute_input":"2023-11-16T13:41:32.125704Z","iopub.status.idle":"2023-11-16T13:41:49.429766Z","shell.execute_reply.started":"2023-11-16T13:41:32.125672Z","shell.execute_reply":"2023-11-16T13:41:49.426999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mfccs.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:41:49.442058Z","iopub.execute_input":"2023-11-16T13:41:49.449653Z","iopub.status.idle":"2023-11-16T13:41:49.475025Z","shell.execute_reply.started":"2023-11-16T13:41:49.449430Z","shell.execute_reply":"2023-11-16T13:41:49.472790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delta.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:41:53.138523Z","iopub.execute_input":"2023-11-16T13:41:53.139089Z","iopub.status.idle":"2023-11-16T13:41:53.147843Z","shell.execute_reply.started":"2023-11-16T13:41:53.139041Z","shell.execute_reply":"2023-11-16T13:41:53.146384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delta_delta.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:41:55.685288Z","iopub.execute_input":"2023-11-16T13:41:55.685801Z","iopub.status.idle":"2023-11-16T13:41:55.694378Z","shell.execute_reply.started":"2023-11-16T13:41:55.685760Z","shell.execute_reply":"2023-11-16T13:41:55.693068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:42:23.278926Z","iopub.execute_input":"2023-11-16T13:42:23.279397Z","iopub.status.idle":"2023-11-16T13:42:23.288385Z","shell.execute_reply.started":"2023-11-16T13:42:23.279363Z","shell.execute_reply":"2023-11-16T13:42:23.286920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flat_mfcc.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:42:30.564946Z","iopub.execute_input":"2023-11-16T13:42:30.565451Z","iopub.status.idle":"2023-11-16T13:42:30.572499Z","shell.execute_reply.started":"2023-11-16T13:42:30.565415Z","shell.execute_reply":"2023-11-16T13:42:30.571555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_mapping","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:42:33.284418Z","iopub.execute_input":"2023-11-16T13:42:33.284936Z","iopub.status.idle":"2023-11-16T13:42:33.295551Z","shell.execute_reply.started":"2023-11-16T13:42:33.284894Z","shell.execute_reply":"2023-11-16T13:42:33.294083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directory containing the folders for each class\nparent_directory = \"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand\"\n\n#PARENT LIST\nclass_mfcc_list=[]\nclass_label_list=[]\n\n#LIST FOR EACH CLASS\nmfccs_list = []\nlabels = []\nmax_mfcc_length =63\n\n# Iterate through each class\nfor class_name, class_label in class_mapping.items():\n    class_directory = os.path.join(parent_directory, class_name)\n    mfccs_list = []\n    labels = []\n\n    # Iterate through audio files in the directory\n    for filename in os.listdir(class_directory):\n        if filename.endswith(\".wav\"):  # Assuming the audio files are in WAV format\n            file_path = os.path.join(class_directory, filename)\n\n            # Load the audio file and extract MFCCs\n            audio_data, sample_rate = librosa.load(file_path, sr=None)\n            mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13,hop_length=256)\n\n            # Pad or truncate the MFCCs to a common length\n            if mfccs.shape[1] < max_mfcc_length:\n                # Pad the MFCCs with zeros to reach the desired length\n                mfccs = np.pad(mfccs, ((0, 0), (0, max_mfcc_length - mfccs.shape[1])), mode='constant')\n            else:\n                # Truncate the MFCCs to the desired length\n                mfccs = mfccs[:, :max_mfcc_length]\n\n            # Extract Delta and Delta-Delta Coefficients\n            delta = librosa.feature.delta(mfccs)\n            delta_delta = librosa.feature.delta(mfccs, order=2)\n\n            # Combine features into a single feature matrix, stacking horizontally\n            features = np.hstack([mfccs, delta, delta_delta])\n            flat_mfcc = features.reshape(1, -1)\n\n            # Append the extracted MFCCs to the list\n            mfccs_list.append(flat_mfcc)\n            labels.append(class_label)\n    \n    mfccs_array = np.array(mfccs_list)\n    class_mfcc_list.append(mfccs_array)\n    class_label_list.append(labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T13:42:47.432936Z","iopub.execute_input":"2023-11-16T13:42:47.433475Z","iopub.status.idle":"2023-11-16T14:09:08.366886Z","shell.execute_reply.started":"2023-11-16T13:42:47.433437Z","shell.execute_reply":"2023-11-16T14:09:08.365083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(class_mfcc_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:09:55.223357Z","iopub.execute_input":"2023-11-16T14:09:55.223903Z","iopub.status.idle":"2023-11-16T14:09:55.233320Z","shell.execute_reply.started":"2023-11-16T14:09:55.223861Z","shell.execute_reply":"2023-11-16T14:09:55.231935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(class_mfcc_list[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:09:57.534120Z","iopub.execute_input":"2023-11-16T14:09:57.534597Z","iopub.status.idle":"2023-11-16T14:09:57.542451Z","shell.execute_reply.started":"2023-11-16T14:09:57.534562Z","shell.execute_reply":"2023-11-16T14:09:57.541181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_mfcc_list[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:35.082253Z","iopub.execute_input":"2023-11-16T14:10:35.082715Z","iopub.status.idle":"2023-11-16T14:10:35.091915Z","shell.execute_reply.started":"2023-11-16T14:10:35.082682Z","shell.execute_reply":"2023-11-16T14:10:35.090405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_mfcc_list[1].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:10:53.362216Z","iopub.execute_input":"2023-11-16T14:10:53.362676Z","iopub.status.idle":"2023-11-16T14:10:53.371626Z","shell.execute_reply.started":"2023-11-16T14:10:53.362643Z","shell.execute_reply":"2023-11-16T14:10:53.370257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_mfcc_list[20].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:11:03.661356Z","iopub.execute_input":"2023-11-16T14:11:03.661830Z","iopub.status.idle":"2023-11-16T14:11:03.670255Z","shell.execute_reply.started":"2023-11-16T14:11:03.661794Z","shell.execute_reply":"2023-11-16T14:11:03.669048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gmm_feature_class_mfcc_list=[]\nfor i in class_mfcc_list:\n\n    # Reshape the data to have two dimensions\n    feature_vector_reshaped =np.reshape(i,(i.shape[0],i.shape[2]))\n    gmm_feature_class_mfcc_list.append(feature_vector_reshaped)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:11:45.595553Z","iopub.execute_input":"2023-11-16T14:11:45.596108Z","iopub.status.idle":"2023-11-16T14:11:45.604242Z","shell.execute_reply.started":"2023-11-16T14:11:45.596063Z","shell.execute_reply":"2023-11-16T14:11:45.602696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(gmm_feature_class_mfcc_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:11:54.480050Z","iopub.execute_input":"2023-11-16T14:11:54.480564Z","iopub.status.idle":"2023-11-16T14:11:54.488861Z","shell.execute_reply.started":"2023-11-16T14:11:54.480522Z","shell.execute_reply":"2023-11-16T14:11:54.487511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gmm_feature_class_mfcc_list[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:12:02.292354Z","iopub.execute_input":"2023-11-16T14:12:02.292855Z","iopub.status.idle":"2023-11-16T14:12:02.301837Z","shell.execute_reply.started":"2023-11-16T14:12:02.292817Z","shell.execute_reply":"2023-11-16T14:12:02.300377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gmm_feature_class_mfcc_list[20].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:12:18.186830Z","iopub.execute_input":"2023-11-16T14:12:18.187338Z","iopub.status.idle":"2023-11-16T14:12:18.196161Z","shell.execute_reply.started":"2023-11-16T14:12:18.187298Z","shell.execute_reply":"2023-11-16T14:12:18.194703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.mixture import GaussianMixture\n# import numpy as np\n\n# # Assuming your feature matrix is stored in the variable 'features'\n# # features.shape should be (m, n)\n\n# # Choose a range of possible numbers of components\n# components_range = range(1, 30)\n\n# # Fit GMMs with different numbers of components and compute BIC\n# bic_values = []\n\n# for n_components in components_range:\n#     gmm = GaussianMixture(n_components=n_components, random_state=42)\n#     gmm.fit(gmm_feature_class_mfcc_list[0])\n#     bic_values.append(gmm.bic(gmm_feature_class_mfcc_list[0]))\n\n# # Find the optimal number of components with the lowest BIC\n# optimal_components = components_range[np.argmin(bic_values)]\n\n# # Now, 'optimal_components' contains the estimated optimal number of components\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimal_components","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.mixture import GaussianMixture\n# import numpy as np\n\n# # Assuming your feature matrix is stored in the variable 'features'\n# # features.shape should be (m, n)\n\n# optimal_components_list=[]\n\n# for i in gmm_feature_class_mfcc_list:\n    \n    \n\n#     # Choose a range of possible numbers of components\n#     components_range = range(1, 15)\n\n#     # Fit GMMs with different numbers of components and compute BIC\n#     bic_values = []\n\n#     for n_components in components_range:\n#         gmm = GaussianMixture(n_components=n_components, random_state=42)\n#         gmm.fit(i)\n#         bic_values.append(gmm.bic(i))\n\n#     # Find the optimal number of components with the lowest BIC\n#     optimal_components = components_range[np.argmin(bic_values)]\n#     optimal_components_list.append(optimal_components)\n\n#     # Now, 'optimal_components' contains the estimated optimal number of components\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimal_components_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\n\n# PARENT LIST\nclass_gmms = {}\n\n# Iterate through each class\nfor class_label, features in zip(class_label_list, gmm_feature_class_mfcc_list):\n    # Assuming features is a 2D array (samples, features)\n    \n    # Initialize and train a GMM model for the current class\n    gmm = GaussianMixture(n_components=3, covariance_type='diag', random_state=42)\n    gmm.fit(features)\n\n    # Store the GMM model in the dictionary with the class label as the key\n    class_gmms[class_label[0]] = gmm","metadata":{"execution":{"iopub.status.busy":"2023-11-16T14:15:12.215721Z","iopub.execute_input":"2023-11-16T14:15:12.216248Z","iopub.status.idle":"2023-11-16T14:16:51.519619Z","shell.execute_reply.started":"2023-11-16T14:15:12.216209Z","shell.execute_reply":"2023-11-16T14:16:51.517896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TEST DATA MFCC EXTRACTION","metadata":{}},{"cell_type":"code","source":"# Directory containing the folders for each class\nparent_test_directory = \"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommandTest\"\n\n# PARENT LIST\nclass_mfcc_test_list = []\n\n# Iterate through audio files in the directory\nfor filename in os.listdir(parent_test_directory):\n    mfccs_list = []  # Initialize list for each audio file\n    if filename.endswith(\".wav\"):  # Assuming the audio files are in WAV format\n        file_path = os.path.join(parent_test_directory, filename)\n\n        # Load the audio file and extract MFCCs\n        audio_data, sample_rate = librosa.load(file_path, sr=None)\n        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13, hop_length=256)\n\n        # Pad or truncate the MFCCs to a common length\n        max_mfcc_length = 63  # You can define this outside the loop if it's constant\n        if mfccs.shape[1] < max_mfcc_length:\n            # Pad the MFCCs with zeros to reach the desired length\n            mfccs = np.pad(mfccs, ((0, 0), (0, max_mfcc_length - mfccs.shape[1])), mode='constant')\n        else:\n            # Truncate the MFCCs to the desired length\n            mfccs = mfccs[:, :max_mfcc_length]\n\n        # Extract Delta and Delta-Delta Coefficients\n        delta = librosa.feature.delta(mfccs)\n        delta_delta = librosa.feature.delta(mfccs, order=2)\n\n        # Combine features into a single feature matrix, stacking horizontally\n        features = np.hstack([mfccs, delta, delta_delta])\n        flat_mfcc = features.reshape(1, -1)\n\n        # Append the extracted MFCCs to the list\n        mfccs_list.append(flat_mfcc)\n    \n    class_mfcc_test_list.append(mfccs_list)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:05:42.759712Z","iopub.execute_input":"2023-11-16T15:05:42.760260Z","iopub.status.idle":"2023-11-16T15:08:18.214389Z","shell.execute_reply.started":"2023-11-16T15:05:42.760220Z","shell.execute_reply":"2023-11-16T15:08:18.212525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir(parent_test_directory))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:08:54.081131Z","iopub.execute_input":"2023-11-16T15:08:54.081579Z","iopub.status.idle":"2023-11-16T15:08:54.093760Z","shell.execute_reply.started":"2023-11-16T15:08:54.081546Z","shell.execute_reply":"2023-11-16T15:08:54.092542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(class_mfcc_test_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:08:57.369704Z","iopub.execute_input":"2023-11-16T15:08:57.370207Z","iopub.status.idle":"2023-11-16T15:08:57.378247Z","shell.execute_reply.started":"2023-11-16T15:08:57.370168Z","shell.execute_reply":"2023-11-16T15:08:57.376836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(class_mfcc_test_list[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:11:09.858384Z","iopub.execute_input":"2023-11-16T15:11:09.858904Z","iopub.status.idle":"2023-11-16T15:11:09.866735Z","shell.execute_reply.started":"2023-11-16T15:11:09.858863Z","shell.execute_reply":"2023-11-16T15:11:09.865518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # List to store predicted labels for test audio\n# predicted_labels = []\n\n# # Iterate through test audio features\n# for test_audio_features in class_mfcc_test_list:  # Replace with your test audio features list\n#     likelihoods = {}\n    \n#     # Calculate likelihood score for each class\n#     for class_label, gmm_model in class_gmms.items():\n#         likelihood = np.mean(gmm_model.score_samples(test_audio_features))\n#         likelihoods[class_label] = likelihood\n    \n#     # Assign label based on the GMM with the highest likelihood score\n#     predicted_label = max(likelihoods, key=likelihoods.get)\n#     predicted_labels.append(predicted_label)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:19:50.258635Z","iopub.execute_input":"2023-11-16T15:19:50.259156Z","iopub.status.idle":"2023-11-16T15:19:50.635828Z","shell.execute_reply.started":"2023-11-16T15:19:50.259121Z","shell.execute_reply":"2023-11-16T15:19:50.634132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing for one audio file\n# Load audio file (replace 'your_audio_file.wav' with the actual file path)\naudio_data, sample_rate = librosa.load('/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommandTest/A_00c40e715_nohash_0.wav', sr=None)\n\n# Extract MFCCs with a larger hop_length to increase the number of frames\nmfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13, hop_length=256)\n\n# Extract Delta and Delta-Delta Coefficients\ndelta = librosa.feature.delta(mfccs)\ndelta_delta = librosa.feature.delta(mfccs, order=2)\n\n# Combine features into a single feature matrix,stacking horizontally\nfeatures = np.hstack([mfccs, delta, delta_delta])\nflat_mfcc = features.reshape(1, -1)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:25:48.974025Z","iopub.execute_input":"2023-11-16T15:25:48.975375Z","iopub.status.idle":"2023-11-16T15:25:49.007284Z","shell.execute_reply.started":"2023-11-16T15:25:48.975330Z","shell.execute_reply":"2023-11-16T15:25:49.005524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flat_mfcc.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:25:58.823668Z","iopub.execute_input":"2023-11-16T15:25:58.824187Z","iopub.status.idle":"2023-11-16T15:25:58.832130Z","shell.execute_reply.started":"2023-11-16T15:25:58.824150Z","shell.execute_reply":"2023-11-16T15:25:58.831169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Your test audio features (replace this with your actual test audio features)\n# single_test_audio_features = ...  # Shape should be (1, num_features)\n\n# Calculate likelihood scores for the test audio features with each GMM model\nlikelihoods = {}\nfor class_label, gmm_model in class_gmms.items():  # Iterate through your trained GMM models\n    likelihood = gmm_model.score_samples(flat_mfcc)\n    likelihoods[class_label] = likelihood\n\n# Predict the label based on the GMM with the highest likelihood score\npredicted_label = max(likelihoods, key=likelihoods.get)\nprint(\"Predicted Label:\", predicted_label)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:26:18.703397Z","iopub.execute_input":"2023-11-16T15:26:18.703906Z","iopub.status.idle":"2023-11-16T15:26:18.728417Z","shell.execute_reply.started":"2023-11-16T15:26:18.703866Z","shell.execute_reply":"2023-11-16T15:26:18.726758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List to store predicted labels\npredicted_labels_list = []\nmax_mfcc_length = 63  # You can define this outside the loop if it's constant\n\n# Iterate through each test audio file\nfor file_path in os.listdir(parent_test_directory):\n    file_path=os.path.join(parent_test_directory,file_path)\n    # Load audio file\n    audio_data, sample_rate = librosa.load(file_path, sr=None)\n    \n    # Extract MFCCs\n    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13, hop_length=256)\n    # Pad or truncate the MFCCs to a common length\n    if mfccs.shape[1] < max_mfcc_length:\n        # Pad the MFCCs with zeros to reach the desired length\n        mfccs = np.pad(mfccs, ((0, 0), (0, max_mfcc_length - mfccs.shape[1])), mode='constant')\n    else:\n        # Truncate the MFCCs to the desired length\n        mfccs = mfccs[:, :max_mfcc_length]\n    delta = librosa.feature.delta(mfccs)\n    delta_delta = librosa.feature.delta(mfccs, order=2)\n    \n    # Combine features into a single feature matrix\n    features = np.hstack([mfccs, delta, delta_delta])\n    flat_mfcc = features.reshape(1, -1)\n    \n    # Calculate likelihood scores for the test audio features with each GMM model\n    likelihoods = {}\n    for class_label, gmm_model in class_gmms.items():  # Iterate through your trained GMM models\n        likelihood = gmm_model.score_samples(flat_mfcc)\n        likelihoods[class_label] = likelihood\n    \n    # Predict the label based on the GMM with the highest likelihood score\n    predicted_label = max(likelihoods, key=likelihoods.get)\n    \n    # Append predicted label to the list\n    predicted_labels_list.append(predicted_label)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:34:18.753416Z","iopub.execute_input":"2023-11-16T15:34:18.753947Z","iopub.status.idle":"2023-11-16T15:39:50.009426Z","shell.execute_reply.started":"2023-11-16T15:34:18.753908Z","shell.execute_reply":"2023-11-16T15:39:50.007623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predicted_labels_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:39:50.011911Z","iopub.execute_input":"2023-11-16T15:39:50.012807Z","iopub.status.idle":"2023-11-16T15:39:50.023600Z","shell.execute_reply.started":"2023-11-16T15:39:50.012757Z","shell.execute_reply":"2023-11-16T15:39:50.021969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv(\"/kaggle/input/test-csv/test (1).csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:43:20.267825Z","iopub.execute_input":"2023-11-16T15:43:20.268377Z","iopub.status.idle":"2023-11-16T15:43:20.307891Z","shell.execute_reply.started":"2023-11-16T15:43:20.268333Z","shell.execute_reply":"2023-11-16T15:43:20.306637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['TARGET']=predicted_labels_list\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:46:14.631647Z","iopub.execute_input":"2023-11-16T15:46:14.632190Z","iopub.status.idle":"2023-11-16T15:46:14.642600Z","shell.execute_reply.started":"2023-11-16T15:46:14.632153Z","shell.execute_reply":"2023-11-16T15:46:14.641261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:46:23.518979Z","iopub.execute_input":"2023-11-16T15:46:23.520363Z","iopub.status.idle":"2023-11-16T15:46:23.532544Z","shell.execute_reply.started":"2023-11-16T15:46:23.520307Z","shell.execute_reply":"2023-11-16T15:46:23.531685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(columns=['AUDIO_FILE'], inplace=True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:46:58.974970Z","iopub.execute_input":"2023-11-16T15:46:58.975465Z","iopub.status.idle":"2023-11-16T15:46:58.995648Z","shell.execute_reply.started":"2023-11-16T15:46:58.975428Z","shell.execute_reply":"2023-11-16T15:46:58.994425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save DataFrame to a CSV file\ndata.to_csv('predicted_labels.csv', index=False)  # Change 'predicted_labels.csv' to your desired file name\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T15:47:55.381630Z","iopub.execute_input":"2023-11-16T15:47:55.382193Z","iopub.status.idle":"2023-11-16T15:47:55.406370Z","shell.execute_reply.started":"2023-11-16T15:47:55.382152Z","shell.execute_reply":"2023-11-16T15:47:55.405200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## APPROACH 3\n","metadata":{}},{"cell_type":"code","source":"background_path='/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand/_background_noise_'\nbackground_noise=os.listdir(background_path)\nbackground_noise.pop(2)\nbackground_noise","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:12:41.617966Z","iopub.execute_input":"2023-11-17T17:12:41.619133Z","iopub.status.idle":"2023-11-17T17:12:41.641024Z","shell.execute_reply.started":"2023-11-17T17:12:41.619086Z","shell.execute_reply":"2023-11-17T17:12:41.639542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mfcc_list = []\ndelta_list = []\ndelta_delta_list = []\nfor audio in background_noise:\n    file_path=os.path.join(background_path,audio)\n    audio_data, sample_rate = librosa.load(file_path, sr=None)  # Use sr=None to preserve the native sample rate\n\n    # Step 3: Segment the Audio\n    frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n    hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n    frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n    # Step 4: MFCC Calculation\n    n_mfcc = 13  # Number of MFCC coefficients\n    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n    delta = librosa.feature.delta(mfccs)\n    delta_delta = librosa.feature.delta(mfccs, order=2)\n    \n    # Append features to respective lists\n    mfcc_list.append(mfccs.T)  # Transpose for having columns equal to coefficients\n    delta_list.append(delta.T)\n    delta_delta_list.append(delta_delta.T)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:08:15.138356Z","iopub.execute_input":"2023-11-17T13:08:15.138788Z","iopub.status.idle":"2023-11-17T13:08:29.838590Z","shell.execute_reply.started":"2023-11-17T13:08:15.138754Z","shell.execute_reply":"2023-11-17T13:08:29.836859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(mfcc_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:08:29.840964Z","iopub.execute_input":"2023-11-17T13:08:29.841805Z","iopub.status.idle":"2023-11-17T13:08:29.860708Z","shell.execute_reply.started":"2023-11-17T13:08:29.841743Z","shell.execute_reply":"2023-11-17T13:08:29.859209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(mfcc_list[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:08:29.863637Z","iopub.execute_input":"2023-11-17T13:08:29.873990Z","iopub.status.idle":"2023-11-17T13:08:29.883343Z","shell.execute_reply.started":"2023-11-17T13:08:29.873930Z","shell.execute_reply":"2023-11-17T13:08:29.881898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mfcc_list[1].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:08:29.889820Z","iopub.execute_input":"2023-11-17T13:08:29.893661Z","iopub.status.idle":"2023-11-17T13:08:29.904938Z","shell.execute_reply.started":"2023-11-17T13:08:29.893588Z","shell.execute_reply":"2023-11-17T13:08:29.903527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mfcc_list[2].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:08:29.907122Z","iopub.execute_input":"2023-11-17T13:08:29.907656Z","iopub.status.idle":"2023-11-17T13:08:29.915802Z","shell.execute_reply.started":"2023-11-17T13:08:29.907612Z","shell.execute_reply":"2023-11-17T13:08:29.914840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert lists to numpy arrays\nmfcc_features = np.concatenate(mfcc_list)\ndelta_features = np.concatenate(delta_list)\ndelta_delta_features = np.concatenate(delta_delta_list)\n\n# Print the shapes to verify dimensions\nprint(\"MFCC shape:\", mfcc_features.shape)\nprint(\"Delta shape:\", delta_features.shape)\nprint(\"Delta-Delta shape:\", delta_delta_features.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:08:29.916916Z","iopub.execute_input":"2023-11-17T13:08:29.917200Z","iopub.status.idle":"2023-11-17T13:08:29.928149Z","shell.execute_reply.started":"2023-11-17T13:08:29.917175Z","shell.execute_reply":"2023-11-17T13:08:29.927112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(mfcc_features)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:08:29.929339Z","iopub.execute_input":"2023-11-17T13:08:29.929645Z","iopub.status.idle":"2023-11-17T13:08:29.935574Z","shell.execute_reply.started":"2023-11-17T13:08:29.929619Z","shell.execute_reply":"2023-11-17T13:08:29.934871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_list","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:08:29.936516Z","iopub.execute_input":"2023-11-17T13:08:29.937240Z","iopub.status.idle":"2023-11-17T13:08:29.947008Z","shell.execute_reply.started":"2023-11-17T13:08:29.937211Z","shell.execute_reply":"2023-11-17T13:08:29.945941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_mapping","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:08:29.948041Z","iopub.execute_input":"2023-11-17T13:08:29.948674Z","iopub.status.idle":"2023-11-17T13:08:29.957629Z","shell.execute_reply.started":"2023-11-17T13:08:29.948641Z","shell.execute_reply":"2023-11-17T13:08:29.956467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directory containing the folders for each class\nparent_directory = \"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand\"\n\n#PARENT LIST\nclass_mfcc_list=[]\ndelta_mfcc_list=[]\ndelta_delta_mfcc_list=[]\nclass_label_list=[]\n\n#LIST FOR EACH CLASS\nmfccs_list = []\ndelta_list=[]\ndelta_delta_list=[]\nlabels = []\n\n# Iterate through each class\nfor class_name, class_label in class_mapping.items():\n    class_directory = os.path.join(parent_directory, class_name)\n    mfccs_list = []\n    delta_list=[]\n    delta_delta_list=[]\n    labels = []\n\n    # Iterate through audio files in the directory\n    for filename in os.listdir(class_directory):\n        if filename.endswith(\".wav\"):  # Assuming the audio files are in WAV format\n            file_path=os.path.join(class_directory,filename)\n            audio_data, sample_rate = librosa.load(file_path, sr=None)  # Use sr=None to preserve the native sample rate\n\n            # Step 3: Segment the Audio\n            frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n            hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n            frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n            # Step 4: MFCC Calculation\n            n_mfcc = 13  # Number of MFCC coefficients\n            mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n            delta = librosa.feature.delta(mfccs)\n            delta_delta = librosa.feature.delta(mfccs, order=2)\n    \n            # Append features to respective lists\n            mfccs_list.append(mfccs.T)  # Transpose for having columns equal to coefficients\n            delta_list.append(delta.T)\n            delta_delta_list.append(delta_delta.T)\n            labels.append(class_label)\n            \n    # Convert lists to numpy arrays\n    mfcc_features = np.concatenate(mfccs_list)\n    delta_features = np.concatenate(delta_list)\n    delta_delta_features = np.concatenate(delta_delta_list)\n    \n    class_mfcc_list.append(mfcc_features)\n    delta_mfcc_list.append(delta_features)\n    delta_delta_mfcc_list.append(delta_delta_features)\n    class_label_list.append(labels)\n            \n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:08:29.960447Z","iopub.execute_input":"2023-11-17T13:08:29.961131Z","iopub.status.idle":"2023-11-17T13:32:32.180856Z","shell.execute_reply.started":"2023-11-17T13:08:29.961080Z","shell.execute_reply":"2023-11-17T13:32:32.163870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(class_mfcc_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:04:39.092994Z","iopub.execute_input":"2023-11-18T14:04:39.093435Z","iopub.status.idle":"2023-11-18T14:04:39.142637Z","shell.execute_reply.started":"2023-11-18T14:04:39.093403Z","shell.execute_reply":"2023-11-18T14:04:39.140990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_mfcc_list[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:32:32.216059Z","iopub.execute_input":"2023-11-17T13:32:32.216447Z","iopub.status.idle":"2023-11-17T13:32:32.238813Z","shell.execute_reply.started":"2023-11-17T13:32:32.216414Z","shell.execute_reply":"2023-11-17T13:32:32.236816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(class_mfcc_list[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:32:32.240290Z","iopub.execute_input":"2023-11-17T13:32:32.240800Z","iopub.status.idle":"2023-11-17T13:32:32.252319Z","shell.execute_reply.started":"2023-11-17T13:32:32.240761Z","shell.execute_reply":"2023-11-17T13:32:32.251530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\n\n# PARENT LIST\nclass_gmms = {}\n\n# Iterate through each class\nfor class_label, features in zip(class_label_list, class_mfcc_list):\n    # Assuming features is a 2D array (samples, features)\n    \n    # Initialize and train a GMM model for the current class\n    gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=42)\n    gmm.fit(features)\n\n    # Store the GMM model in the dictionary with the class label as the key\n    class_gmms[class_label[0]] = gmm","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:32:32.253574Z","iopub.execute_input":"2023-11-17T13:32:32.254080Z","iopub.status.idle":"2023-11-17T13:34:22.092232Z","shell.execute_reply.started":"2023-11-17T13:32:32.254052Z","shell.execute_reply":"2023-11-17T13:34:22.090403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TEST DATA","metadata":{}},{"cell_type":"code","source":"test_data_directory=\"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommandTest\"\ntest_data_list=os.listdir(test_data_directory)\n# len(test_data_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:34:22.094440Z","iopub.execute_input":"2023-11-17T13:34:22.095400Z","iopub.status.idle":"2023-11-17T13:34:22.550765Z","shell.execute_reply.started":"2023-11-17T13:34:22.095333Z","shell.execute_reply":"2023-11-17T13:34:22.549405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_data_list[0:10]","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:40:48.921979Z","iopub.execute_input":"2023-11-17T13:40:48.922797Z","iopub.status.idle":"2023-11-17T13:40:48.928900Z","shell.execute_reply.started":"2023-11-17T13:40:48.922759Z","shell.execute_reply":"2023-11-17T13:40:48.927896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv(\"/kaggle/input/test-csv/test (1).csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:40:16.034794Z","iopub.execute_input":"2023-11-17T13:40:16.035274Z","iopub.status.idle":"2023-11-17T13:40:16.061795Z","shell.execute_reply.started":"2023-11-17T13:40:16.035238Z","shell.execute_reply":"2023-11-17T13:40:16.061018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_file_columns=data['AUDIO_FILE']\ntest_data_list=audio_file_columns.to_list()\nlen(test_data_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:45:06.989498Z","iopub.execute_input":"2023-11-17T13:45:06.990358Z","iopub.status.idle":"2023-11-17T13:45:06.996104Z","shell.execute_reply.started":"2023-11-17T13:45:06.990323Z","shell.execute_reply":"2023-11-17T13:45:06.995334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_mfcc_list = []\ntest_delta_list = []\ntest_delta_delta_list = []\nfor audio in test_data_list:\n    file_path=os.path.join(test_data_directory,audio)\n    audio_data, sample_rate = librosa.load(file_path, sr=None)  # Use sr=None to preserve the native sample rate\n\n    # Step 3: Segment the Audio\n    frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n    hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n    frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n    # Step 4: MFCC Calculation\n    n_mfcc = 13  # Number of MFCC coefficients\n    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n    delta = librosa.feature.delta(mfccs)\n    delta_delta = librosa.feature.delta(mfccs, order=2)\n    \n    # Append features to respective lists\n    test_mfcc_list.append(mfccs.T)  # Transpose for having columns equal to coefficients\n    test_delta_list.append(delta.T)\n    test_delta_delta_list.append(delta_delta.T)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:45:14.487228Z","iopub.execute_input":"2023-11-17T13:45:14.487688Z","iopub.status.idle":"2023-11-17T13:46:56.746639Z","shell.execute_reply.started":"2023-11-17T13:45:14.487649Z","shell.execute_reply":"2023-11-17T13:46:56.745059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_mfcc_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:46:56.755311Z","iopub.execute_input":"2023-11-17T13:46:56.759248Z","iopub.status.idle":"2023-11-17T13:46:56.774344Z","shell.execute_reply.started":"2023-11-17T13:46:56.759186Z","shell.execute_reply":"2023-11-17T13:46:56.772970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_mfcc_list[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:46:56.781257Z","iopub.execute_input":"2023-11-17T13:46:56.785086Z","iopub.status.idle":"2023-11-17T13:46:56.800150Z","shell.execute_reply.started":"2023-11-17T13:46:56.785026Z","shell.execute_reply":"2023-11-17T13:46:56.798693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels_list = []\n\nfor features in test_mfcc_list:\n    likelihoods = {}\n    \n    for class_label, gmm_model in class_gmms.items():  # Iterate through your trained GMM models\n        likelihood= gmm_model.score(features)\n        \n        likelihoods[class_label] = likelihood\n    \n    # Predict the label based on the GMM with the highest likelihood score\n    predicted_label = max(likelihoods, key=likelihoods.get)\n    \n    # Append predicted label to the list\n    predicted_labels_list.append(predicted_label)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:46:56.806776Z","iopub.execute_input":"2023-11-17T13:46:56.811834Z","iopub.status.idle":"2023-11-17T13:48:00.861727Z","shell.execute_reply.started":"2023-11-17T13:46:56.811776Z","shell.execute_reply":"2023-11-17T13:48:00.860804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predicted_labels_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:48:00.862892Z","iopub.execute_input":"2023-11-17T13:48:00.863187Z","iopub.status.idle":"2023-11-17T13:48:00.869326Z","shell.execute_reply.started":"2023-11-17T13:48:00.863162Z","shell.execute_reply":"2023-11-17T13:48:00.868324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv(\"/kaggle/input/test-csv/test (1).csv\")\ndata['TARGET']=predicted_labels_list\ndata.drop(columns=['AUDIO_FILE'], inplace=True)\n# Save DataFrame to a CSV file\ndata.to_csv('predicted_labels.csv', index=False)  # Change 'predicted_labels.csv' to your desired file name\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T13:48:00.870662Z","iopub.execute_input":"2023-11-17T13:48:00.870996Z","iopub.status.idle":"2023-11-17T13:48:00.909033Z","shell.execute_reply.started":"2023-11-17T13:48:00.870969Z","shell.execute_reply":"2023-11-17T13:48:00.907951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## APPROACH 4","metadata":{}},{"cell_type":"code","source":"background_path='/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand/_background_noise_'\nbackground_noise=os.listdir(background_path)\nbackground_noise.pop(2)\nbackground_noise","metadata":{"execution":{"iopub.status.busy":"2023-11-19T02:41:04.203580Z","iopub.execute_input":"2023-11-19T02:41:04.204089Z","iopub.status.idle":"2023-11-19T02:41:04.223789Z","shell.execute_reply.started":"2023-11-19T02:41:04.204051Z","shell.execute_reply":"2023-11-19T02:41:04.222732Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['exercise_bike.wav',\n 'pink_noise.wav',\n 'running_tap.wav',\n 'white_noise.wav',\n 'doing_the_dishes.wav',\n 'dude_miaowing.wav']"},"metadata":{}}]},{"cell_type":"code","source":"mfcc_list = []\ndelta_list = []\ndelta_delta_list = []\nfor audio in background_noise:\n    file_path=os.path.join(background_path,audio)\n    audio_data, sample_rate = librosa.load(file_path, sr=None)  # Use sr=None to preserve the native sample rate\n\n    # Step 3: Segment the Audio\n    frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n    hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n    frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n    # Step 4: MFCC Calculation\n    n_mfcc = 13  # Number of MFCC coefficients\n    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n    delta = librosa.feature.delta(mfccs)\n    delta_delta = librosa.feature.delta(mfccs, order=2)\n    \n    # Append features to respective lists\n    mfcc_list.append(mfccs.T)  # Transpose for having columns equal to coefficients\n    delta_list.append(delta.T)\n    delta_delta_list.append(delta_delta.T)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T02:41:08.815230Z","iopub.execute_input":"2023-11-19T02:41:08.815673Z","iopub.status.idle":"2023-11-19T02:41:25.593222Z","shell.execute_reply.started":"2023-11-19T02:41:08.815637Z","shell.execute_reply":"2023-11-19T02:41:25.591497Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"len(mfcc_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T02:41:25.596893Z","iopub.execute_input":"2023-11-19T02:41:25.598243Z","iopub.status.idle":"2023-11-19T02:41:25.610624Z","shell.execute_reply.started":"2023-11-19T02:41:25.598165Z","shell.execute_reply":"2023-11-19T02:41:25.608673Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"6"},"metadata":{}}]},{"cell_type":"code","source":"mfcc_list[1].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-19T02:41:25.613454Z","iopub.execute_input":"2023-11-19T02:41:25.614175Z","iopub.status.idle":"2023-11-19T02:41:25.629442Z","shell.execute_reply.started":"2023-11-19T02:41:25.614107Z","shell.execute_reply":"2023-11-19T02:41:25.627215Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(6001, 13)"},"metadata":{}}]},{"cell_type":"code","source":"type(mfcc_list[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-19T02:41:25.633578Z","iopub.execute_input":"2023-11-19T02:41:25.635468Z","iopub.status.idle":"2023-11-19T02:41:25.651591Z","shell.execute_reply.started":"2023-11-19T02:41:25.635396Z","shell.execute_reply":"2023-11-19T02:41:25.649484Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"# Convert lists to numpy arrays\nmfcc_features = np.concatenate(mfcc_list)\ndelta_features = np.concatenate(delta_list)\ndelta_delta_features = np.concatenate(delta_delta_list)\ncombinded_noise_feature=np.hstack((mfcc_features,delta_features,delta_delta_features))\n\n# Print the shapes to verify dimensions\nprint(\"MFCC shape:\", mfcc_features.shape)\nprint(\"Delta shape:\", delta_features.shape)\nprint(\"Delta-Delta shape:\", delta_delta_features.shape)\nprint(\"Combined-features shape:\" ,combinded_noise_feature.shape )","metadata":{"execution":{"iopub.status.busy":"2023-11-19T02:41:29.780093Z","iopub.execute_input":"2023-11-19T02:41:29.780529Z","iopub.status.idle":"2023-11-19T02:41:29.792264Z","shell.execute_reply.started":"2023-11-19T02:41:29.780496Z","shell.execute_reply":"2023-11-19T02:41:29.791067Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"MFCC shape: (39944, 13)\nDelta shape: (39944, 13)\nDelta-Delta shape: (39944, 13)\nCombined-features shape: (39944, 39)\n","output_type":"stream"}]},{"cell_type":"code","source":"type(combinded_noise_feature)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T02:41:33.884431Z","iopub.execute_input":"2023-11-19T02:41:33.884859Z","iopub.status.idle":"2023-11-19T02:41:33.894657Z","shell.execute_reply.started":"2023-11-19T02:41:33.884823Z","shell.execute_reply":"2023-11-19T02:41:33.893106Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"# Directory containing the folders for each class\nparent_directory = \"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand\"\n\n#PARENT LIST\nclass_mfcc_list=[]\ndelta_mfcc_list=[]\ndelta_delta_mfcc_list=[]\ncombined_train_data_list=[]\nclass_label_list=[]\n\n#LIST FOR EACH CLASS\nmfccs_list = []\ndelta_list=[]\ndelta_delta_list=[]\nlabels = []\n\n# Iterate through each class\nfor class_name, class_label in class_mapping.items():\n    class_directory = os.path.join(parent_directory, class_name)\n    mfccs_list = []\n    delta_list=[]\n    delta_delta_list=[]\n    combined_list=[]\n    labels = []\n\n    # Iterate through audio files in the directory\n    for filename in os.listdir(class_directory):\n        if filename.endswith(\".wav\"):  # Assuming the audio files are in WAV format\n            file_path=os.path.join(class_directory,filename)\n            audio_data, sample_rate = librosa.load(file_path, sr=None)  # Use sr=None to preserve the native sample rate\n\n            # Step 3: Segment the Audio\n            frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n            hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n            frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n            # Step 4: MFCC Calculation\n            n_mfcc = 13  # Number of MFCC coefficients\n            mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n            delta = librosa.feature.delta(mfccs)\n            delta_delta = librosa.feature.delta(mfccs, order=2)\n    \n            # Append features to respective lists\n            mfccs_list.append(mfccs.T)  # Transpose for having columns equal to coefficients\n            delta_list.append(delta.T)\n            delta_delta_list.append(delta_delta.T)\n            labels.append(class_label)\n            \n    # Convert lists to numpy arrays\n    mfcc_features = np.concatenate(mfccs_list)\n    delta_features = np.concatenate(delta_list)\n    delta_delta_features = np.concatenate(delta_delta_list)\n    combined_features=np.hstack((mfcc_features,delta_features,delta_delta_features))\n    \n    class_mfcc_list.append(mfcc_features)\n    delta_mfcc_list.append(delta_features)\n    delta_delta_mfcc_list.append(delta_delta_features)\n    combined_train_data_list.append(combined_features)\n    class_label_list.append(labels)\n            \n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T02:41:38.611895Z","iopub.execute_input":"2023-11-19T02:41:38.612327Z","iopub.status.idle":"2023-11-19T03:05:43.452979Z","shell.execute_reply.started":"2023-11-19T02:41:38.612295Z","shell.execute_reply":"2023-11-19T03:05:43.451792Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# #MFCC,DELTA FEATURES\n# # Directory containing the folders for each class\n# parent_directory = \"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommand\"\n\n# #PARENT LIST\n# class_mfcc_list=[]\n# delta_mfcc_list=[]\n# delta_delta_mfcc_list=[]\n# combined_train_data_list=[]\n# class_label_list=[]\n\n# #LIST FOR EACH CLASS\n# mfccs_list = []\n# delta_list=[]\n# delta_delta_list=[]\n# labels = []\n\n# # Iterate through each class\n# for class_name, class_label in class_mapping.items():\n#     class_directory = os.path.join(parent_directory, class_name)\n#     mfccs_list = []\n#     delta_list=[]\n#     delta_delta_list=[]\n#     combined_list=[]\n#     labels = []\n\n#     # Iterate through audio files in the directory\n#     for filename in os.listdir(class_directory):\n#         if filename.endswith(\".wav\"):  # Assuming the audio files are in WAV format\n#             file_path=os.path.join(class_directory,filename)\n#             audio_data, sample_rate = librosa.load(file_path, sr=None)  # Use sr=None to preserve the native sample rate\n\n#             # Step 3: Segment the Audio\n#             frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n#             hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n#             frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n#             # Step 4: MFCC Calculation\n#             n_mfcc = 13  # Number of MFCC coefficients\n#             mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n#             delta = librosa.feature.delta(mfccs)\n#             delta_delta = librosa.feature.delta(mfccs, order=2)\n    \n#             # Append features to respective lists\n#             mfccs_list.append(mfccs.T)  # Transpose for having columns equal to coefficients\n#             delta_list.append(delta.T)\n#             delta_delta_list.append(delta_delta.T)\n#             labels.append(class_label)\n            \n#     # Convert lists to numpy arrays\n#     mfcc_features = np.concatenate(mfccs_list)\n#     delta_features = np.concatenate(delta_list)\n#     delta_delta_features = np.concatenate(delta_delta_list)\n#     combined_features=np.hstack((mfcc_features,delta_features))\n    \n#     class_mfcc_list.append(mfcc_features)\n#     delta_mfcc_list.append(delta_features)\n#     delta_delta_mfcc_list.append(delta_delta_features)\n#     combined_train_data_list.append(combined_features)\n#     class_label_list.append(labels)\n            \n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T18:46:07.905574Z","iopub.execute_input":"2023-11-18T18:46:07.906691Z","iopub.status.idle":"2023-11-18T18:58:11.715396Z","shell.execute_reply.started":"2023-11-18T18:46:07.906641Z","shell.execute_reply":"2023-11-18T18:58:11.714277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(combined_train_data_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T03:05:43.454706Z","iopub.execute_input":"2023-11-19T03:05:43.455340Z","iopub.status.idle":"2023-11-19T03:05:43.464433Z","shell.execute_reply.started":"2023-11-19T03:05:43.455303Z","shell.execute_reply":"2023-11-19T03:05:43.463223Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"30"},"metadata":{}}]},{"cell_type":"code","source":"type(combined_train_data_list[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-19T03:05:43.466045Z","iopub.execute_input":"2023-11-19T03:05:43.466482Z","iopub.status.idle":"2023-11-19T03:05:43.478792Z","shell.execute_reply.started":"2023-11-19T03:05:43.466445Z","shell.execute_reply":"2023-11-19T03:05:43.476504Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"combined_train_data_list[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-19T03:05:43.523083Z","iopub.execute_input":"2023-11-19T03:05:43.523455Z","iopub.status.idle":"2023-11-19T03:05:43.535540Z","shell.execute_reply.started":"2023-11-19T03:05:43.523426Z","shell.execute_reply":"2023-11-19T03:05:43.534357Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(210215, 39)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\n\n# PARENT LIST\nclass_gmms = {}\n\n# Iterate through each class\nfor class_label, features in zip(class_label_list, combined_train_data_list):\n    # Assuming features is a 2D array (samples,features)\n    \n    # Initialize and train a GMM model for the current class\n    gmm = GaussianMixture(n_components=10,covariance_type='full',reg_covar = 0.50, \n    max_iter=150, init_params='k-means++')\n    gmm.fit(features)\n\n    # Store the GMM model in the dictionary with the class label as the key\n    class_gmms[class_label[0]] = gmm","metadata":{"execution":{"iopub.status.busy":"2023-11-19T03:05:43.537346Z","iopub.execute_input":"2023-11-19T03:05:43.537926Z","iopub.status.idle":"2023-11-19T03:55:12.812940Z","shell.execute_reply.started":"2023-11-19T03:05:43.537877Z","shell.execute_reply":"2023-11-19T03:55:12.811492Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# gmm = GaussianMixture(n_components=10,covariance_type='full',reg_covar = 0.50, \n# max_iter=150, init_params='k-means++')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(class_gmms[0].score(combined_train_data_list[0]))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T03:55:12.815261Z","iopub.execute_input":"2023-11-19T03:55:12.815783Z","iopub.status.idle":"2023-11-19T03:55:14.833535Z","shell.execute_reply.started":"2023-11-19T03:55:12.815737Z","shell.execute_reply":"2023-11-19T03:55:14.832244Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"-103.69959069961364\n","output_type":"stream"}]},{"cell_type":"code","source":"# from sklearn.mixture import GaussianMixture\n\n# # PARENT LIST\n# class_gmms = {}\n\n# # Iterate through each class\n# for class_label, features in zip(class_label_list, combined_train_data_list):\n#     # Assuming features is a 2D array (samples, features)\n    \n#     # Initialize and train a GMM model for the current class\n#     gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=42)\n#     gmm.fit(features)\n\n#     # Store the GMM model in the dictionary with the class label as the key\n#     class_gmms[class_label[0]] = gmm","metadata":{"execution":{"iopub.status.busy":"2023-11-18T10:47:54.242364Z","iopub.execute_input":"2023-11-18T10:47:54.242868Z","iopub.status.idle":"2023-11-18T10:52:49.899690Z","shell.execute_reply.started":"2023-11-18T10:47:54.242830Z","shell.execute_reply":"2023-11-18T10:52:49.897850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\nmain_directory = '/kaggle/working/saved_gmms_high'  # Define the main directory path\n\n# Check if the main directory exists, if not, create it\nif not os.path.exists(main_directory):\n    os.makedirs(main_directory)\n\n# Assuming class_gmms is your dictionary of GMM models\nfor label, gmm_model in class_gmms.items():\n    filename = f'gmm_model_{label}.joblib'  # Define a unique filename for each model within the main directory\n    file_path = os.path.join(main_directory, filename)  # Create the complete file path\n    \n    joblib.dump(gmm_model, file_path)  # Save the model to a file within the main directory\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T03:55:14.837986Z","iopub.execute_input":"2023-11-19T03:55:14.838473Z","iopub.status.idle":"2023-11-19T03:55:14.907914Z","shell.execute_reply.started":"2023-11-19T03:55:14.838435Z","shell.execute_reply":"2023-11-19T03:55:14.906636Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Define the directory to zip\ndirectory_to_zip = '/kaggle/working/saved_gmms_high'\n\n# Define the output zip file path\nzip_file_path = '/kaggle/working/saved_gmms_high.zip'\n\n# Create a zip file of the directory\nshutil.make_archive(zip_file_path.split('.zip')[0], 'zip', directory_to_zip)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T03:55:15.352734Z","iopub.execute_input":"2023-11-19T03:55:15.353218Z","iopub.status.idle":"2023-11-19T03:55:15.795395Z","shell.execute_reply.started":"2023-11-19T03:55:15.353173Z","shell.execute_reply":"2023-11-19T03:55:15.794086Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/saved_gmms_high.zip'"},"metadata":{}}]},{"cell_type":"markdown","source":"## TEST DATA","metadata":{}},{"cell_type":"code","source":"test_data_directory=\"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommandTest\"","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:26:21.611546Z","iopub.execute_input":"2023-11-19T04:26:21.611945Z","iopub.status.idle":"2023-11-19T04:26:21.617384Z","shell.execute_reply.started":"2023-11-19T04:26:21.611916Z","shell.execute_reply":"2023-11-19T04:26:21.615942Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv(\"/kaggle/input/test-csv/test (1).csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:26:22.351107Z","iopub.execute_input":"2023-11-19T04:26:22.351572Z","iopub.status.idle":"2023-11-19T04:26:22.409050Z","shell.execute_reply.started":"2023-11-19T04:26:22.351542Z","shell.execute_reply":"2023-11-19T04:26:22.408175Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   ID                   AUDIO_FILE\n0   0  A_66293f2b358d_nohash_0.wav\n1   1  A_3534412c675c_nohash_0.wav\n2   2   A_912e1469561_nohash_2.wav\n3   3  A_301428497c5b_nohash_0.wav\n4   4  A_32884620dc14_nohash_0.wav","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>AUDIO_FILE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>A_66293f2b358d_nohash_0.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>A_3534412c675c_nohash_0.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A_912e1469561_nohash_2.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>A_301428497c5b_nohash_0.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>A_32884620dc14_nohash_0.wav</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"audio_file_columns=data['AUDIO_FILE']\ntest_data_list=audio_file_columns.to_list()\nlen(test_data_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:26:23.665392Z","iopub.execute_input":"2023-11-19T04:26:23.666068Z","iopub.status.idle":"2023-11-19T04:26:23.672708Z","shell.execute_reply.started":"2023-11-19T04:26:23.666010Z","shell.execute_reply":"2023-11-19T04:26:23.671897Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"6835"},"metadata":{}}]},{"cell_type":"code","source":"## MFCC,DELTA FEATURES,DELTA DELTA FEATURES\ntest_mfcc_list = []\ntest_delta_list = []\ntest_delta_delta_list = []\ncombined_test_data_list=[]\nfor audio in test_data_list:\n    file_path=os.path.join(test_data_directory,audio)\n    audio_data, sample_rate = librosa.load(file_path, sr=None)  # Use sr=None to preserve the native sample rate\n\n    # Step 3: Segment the Audio\n    frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n    hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n    frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n    # Step 4: MFCC Calculation\n    n_mfcc = 13  # Number of MFCC coefficients\n    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n    delta = librosa.feature.delta(mfccs)\n    delta_delta = librosa.feature.delta(mfccs, order=2)\n    combined_features=np.hstack((mfccs.T,delta.T,delta_delta.T))\n    \n    # Append features to respective lists\n    test_mfcc_list.append(mfccs.T)  # Transpose for having columns equal to coefficients\n    test_delta_list.append(delta.T)\n    test_delta_delta_list.append(delta_delta.T)\n    combined_test_data_list.append(combined_features)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:26:24.974026Z","iopub.execute_input":"2023-11-19T04:26:24.974440Z","iopub.status.idle":"2023-11-19T04:29:43.552187Z","shell.execute_reply.started":"2023-11-19T04:26:24.974402Z","shell.execute_reply":"2023-11-19T04:29:43.550481Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# ## MFCC,DELTA FEATURES\n# test_mfcc_list = []\n# test_delta_list = []\n# test_delta_delta_list = []\n# combined_test_data_list=[]\n# for audio in test_data_list:\n#     file_path=os.path.join(test_data_directory,audio)\n#     audio_data, sample_rate = librosa.load(file_path, sr=None)  # Use sr=None to preserve the native sample rate\n\n#     # Step 3: Segment the Audio\n#     frame_length = int(sample_rate * 0.025)  # Frame length (25 ms)\n#     hop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\n#     frames = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n#     # Step 4: MFCC Calculation\n#     n_mfcc = 13  # Number of MFCC coefficients\n#     mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\n#     delta = librosa.feature.delta(mfccs)\n#     delta_delta = librosa.feature.delta(mfccs, order=2)\n#     combined_features=np.hstack((mfccs.T,delta.T,delta_delta.T))\n    \n#     # Append features to respective lists\n#     test_mfcc_list.append(mfccs.T)  # Transpose for having columns equal to coefficients\n#     test_delta_list.append(delta.T)\n#     test_delta_delta_list.append(delta_delta.T)\n#     combined_test_data_list.append(combined_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(combined_test_data_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:29:43.562671Z","iopub.execute_input":"2023-11-19T04:29:43.568989Z","iopub.status.idle":"2023-11-19T04:29:43.585902Z","shell.execute_reply.started":"2023-11-19T04:29:43.568892Z","shell.execute_reply":"2023-11-19T04:29:43.584413Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"6835"},"metadata":{}}]},{"cell_type":"code","source":"combined_test_data_list[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:29:43.594446Z","iopub.execute_input":"2023-11-19T04:29:43.596283Z","iopub.status.idle":"2023-11-19T04:29:43.613650Z","shell.execute_reply.started":"2023-11-19T04:29:43.596213Z","shell.execute_reply":"2023-11-19T04:29:43.612100Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(101, 39)"},"metadata":{}}]},{"cell_type":"code","source":"predicted_labels_list = []\n\nfor features in combined_test_data_list:\n    likelihoods = {}\n    \n    for class_label, gmm_model in class_gmms.items():  # Iterate through your trained GMM models\n        likelihood= gmm_model.score(features)\n        \n        likelihoods[class_label] = likelihood\n    \n    # Predict the label based on the GMM with the highest likelihood score\n    predicted_label = max(likelihoods, key=likelihoods.get)\n    \n    # Append predicted label to the list\n    predicted_labels_list.append(predicted_label)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T03:58:17.394770Z","iopub.execute_input":"2023-11-19T03:58:17.396654Z","iopub.status.idle":"2023-11-19T04:01:33.050352Z","shell.execute_reply.started":"2023-11-19T03:58:17.396586Z","shell.execute_reply":"2023-11-19T04:01:33.048726Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv(\"/kaggle/input/test-csv/test (1).csv\")\ndata['TARGET']=predicted_labels_list\ndata.drop(columns=['AUDIO_FILE'], inplace=True)\n# Save DataFrame to a CSV file\ndata.to_csv('predicted_labels.csv', index=False)  # Change 'predicted_labels.csv' to your desired file name\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:01:33.052323Z","iopub.execute_input":"2023-11-19T04:01:33.052698Z","iopub.status.idle":"2023-11-19T04:01:33.103295Z","shell.execute_reply.started":"2023-11-19T04:01:33.052654Z","shell.execute_reply":"2023-11-19T04:01:33.101916Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(\"CODE IS READY\")","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:01:33.114075Z","iopub.execute_input":"2023-11-19T04:01:33.115114Z","iopub.status.idle":"2023-11-19T04:01:33.127217Z","shell.execute_reply.started":"2023-11-19T04:01:33.115073Z","shell.execute_reply":"2023-11-19T04:01:33.126288Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"CODE IS READY\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## TESTING FOR THE SAVED GMM MODEL","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.mixture import GaussianMixture\nimport librosa\nimport joblib","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:29:43.617860Z","iopub.execute_input":"2023-11-19T04:29:43.629444Z","iopub.status.idle":"2023-11-19T04:29:44.154204Z","shell.execute_reply.started":"2023-11-19T04:29:43.629361Z","shell.execute_reply":"2023-11-19T04:29:44.153242Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model_directory=\"/kaggle/input/gm-models\"\nmodels_list=os.listdir(model_directory)\nsorted_model_list=sorted(models_list, key=lambda x: int(x.split('_')[2].split('.')[0]))\nsorted_model_list","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:29:44.155628Z","iopub.execute_input":"2023-11-19T04:29:44.156074Z","iopub.status.idle":"2023-11-19T04:29:44.174121Z","shell.execute_reply.started":"2023-11-19T04:29:44.156034Z","shell.execute_reply":"2023-11-19T04:29:44.173224Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['gmm_model_0.joblib',\n 'gmm_model_1.joblib',\n 'gmm_model_2.joblib',\n 'gmm_model_3.joblib',\n 'gmm_model_4.joblib',\n 'gmm_model_5.joblib',\n 'gmm_model_6.joblib',\n 'gmm_model_7.joblib',\n 'gmm_model_8.joblib',\n 'gmm_model_9.joblib',\n 'gmm_model_10.joblib',\n 'gmm_model_11.joblib',\n 'gmm_model_12.joblib',\n 'gmm_model_13.joblib',\n 'gmm_model_14.joblib',\n 'gmm_model_15.joblib',\n 'gmm_model_16.joblib',\n 'gmm_model_17.joblib',\n 'gmm_model_18.joblib',\n 'gmm_model_19.joblib',\n 'gmm_model_20.joblib',\n 'gmm_model_21.joblib',\n 'gmm_model_22.joblib',\n 'gmm_model_23.joblib',\n 'gmm_model_24.joblib',\n 'gmm_model_25.joblib',\n 'gmm_model_26.joblib',\n 'gmm_model_27.joblib',\n 'gmm_model_28.joblib',\n 'gmm_model_29.joblib']"},"metadata":{}}]},{"cell_type":"code","source":"#TESTING FOR THE SAVED GMM MODEL\nload_gmm_list={}\nlabel=0\n\nfor model in sorted_model_list:\n    model_path=os.path.join(model_directory,model)\n    load_gmm_list[label] = joblib.load(model_path)\n    label=label+1","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:29:44.175489Z","iopub.execute_input":"2023-11-19T04:29:44.175812Z","iopub.status.idle":"2023-11-19T04:29:44.493367Z","shell.execute_reply.started":"2023-11-19T04:29:44.175784Z","shell.execute_reply":"2023-11-19T04:29:44.492235Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"predicted_labels_list = []\n\nfor features in combined_test_data_list:\n    likelihoods = {}\n    \n    for class_label, gmm_model in load_gmm_list.items():  # Iterate through your trained GMM models\n        likelihood= gmm_model.score(features)\n        \n        likelihoods[class_label] = likelihood\n    \n    # Predict the label based on the GMM with the highest likelihood score\n    predicted_label = max(likelihoods, key=likelihoods.get)\n    \n    # Append predicted label to the list\n    predicted_labels_list.append(predicted_label)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:29:44.495167Z","iopub.execute_input":"2023-11-19T04:29:44.496260Z","iopub.status.idle":"2023-11-19T04:32:50.334002Z","shell.execute_reply.started":"2023-11-19T04:29:44.496216Z","shell.execute_reply":"2023-11-19T04:32:50.332920Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv(\"/kaggle/input/test-csv/test (1).csv\")\ndata['TARGET']=predicted_labels_list\ndata.drop(columns=['AUDIO_FILE'], inplace=True)\n# Save DataFrame to a CSV file\ndata.to_csv('predicted_labels_test.csv', index=False)  # Change 'predicted_labels.csv' to your desired file name\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:32:50.335452Z","iopub.execute_input":"2023-11-19T04:32:50.335749Z","iopub.status.idle":"2023-11-19T04:32:50.392422Z","shell.execute_reply.started":"2023-11-19T04:32:50.335723Z","shell.execute_reply":"2023-11-19T04:32:50.391325Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## TEST SCRIPT","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.mixture import GaussianMixture\nimport librosa\nimport joblib\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:05:44.835065Z","iopub.execute_input":"2023-11-19T04:05:44.835577Z","iopub.status.idle":"2023-11-19T04:05:44.841879Z","shell.execute_reply.started":"2023-11-19T04:05:44.835542Z","shell.execute_reply":"2023-11-19T04:05:44.840711Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"##TEST AUDIO FILE\ntest_audio_file_path=\"/kaggle/input/kaggle-2/KAGGLE-2/SpeechCommandTest/A_1000563aa4e6_nohash_1.wav\"","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:05:46.346801Z","iopub.execute_input":"2023-11-19T04:05:46.347213Z","iopub.status.idle":"2023-11-19T04:05:46.353356Z","shell.execute_reply.started":"2023-11-19T04:05:46.347181Z","shell.execute_reply":"2023-11-19T04:05:46.351772Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#Load the test audio data\naudio_data, sample_rate = librosa.load(test_audio_file_path, sr=None)  # Use sr=None to preserve the native sample rate\n\n# Step 3: Segment the Audio\nframe_length = int(sample_rate * 0.025)  # Frame length (25 ms)\nhop_length = int(sample_rate * 0.010)  # Hop length (10 ms)\nframes = librosa.util.frame(audio_data, frame_length=frame_length, hop_length=hop_length)\n\n# Step 4: MFCC Calculation\nn_mfcc = 13  # Number of MFCC coefficients\nmfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc, n_fft=frame_length, hop_length=hop_length)\ndelta = librosa.feature.delta(mfccs)\ndelta_delta = librosa.feature.delta(mfccs, order=2)\ncombined_features=np.hstack((mfccs.T,delta.T,delta_delta.T))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:05:47.627768Z","iopub.execute_input":"2023-11-19T04:05:47.628195Z","iopub.status.idle":"2023-11-19T04:05:47.653027Z","shell.execute_reply.started":"2023-11-19T04:05:47.628160Z","shell.execute_reply":"2023-11-19T04:05:47.651327Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"combined_features.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:05:49.242241Z","iopub.execute_input":"2023-11-19T04:05:49.242708Z","iopub.status.idle":"2023-11-19T04:05:49.250520Z","shell.execute_reply.started":"2023-11-19T04:05:49.242658Z","shell.execute_reply":"2023-11-19T04:05:49.249031Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(101, 39)"},"metadata":{}}]},{"cell_type":"code","source":"type(combined_features)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:05:50.540077Z","iopub.execute_input":"2023-11-19T04:05:50.540492Z","iopub.status.idle":"2023-11-19T04:05:50.547286Z","shell.execute_reply.started":"2023-11-19T04:05:50.540459Z","shell.execute_reply":"2023-11-19T04:05:50.546026Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"model_directory=\"/kaggle/input/gm-models\"\nmodels_list=os.listdir(model_directory)\nsorted_model_list=sorted(models_list, key=lambda x: int(x.split('_')[2].split('.')[0]))\nsorted_model_list","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:06:18.333728Z","iopub.execute_input":"2023-11-19T04:06:18.335028Z","iopub.status.idle":"2023-11-19T04:06:18.352370Z","shell.execute_reply.started":"2023-11-19T04:06:18.334984Z","shell.execute_reply":"2023-11-19T04:06:18.351385Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"['gmm_model_0.joblib',\n 'gmm_model_1.joblib',\n 'gmm_model_2.joblib',\n 'gmm_model_3.joblib',\n 'gmm_model_4.joblib',\n 'gmm_model_5.joblib',\n 'gmm_model_6.joblib',\n 'gmm_model_7.joblib',\n 'gmm_model_8.joblib',\n 'gmm_model_9.joblib',\n 'gmm_model_10.joblib',\n 'gmm_model_11.joblib',\n 'gmm_model_12.joblib',\n 'gmm_model_13.joblib',\n 'gmm_model_14.joblib',\n 'gmm_model_15.joblib',\n 'gmm_model_16.joblib',\n 'gmm_model_17.joblib',\n 'gmm_model_18.joblib',\n 'gmm_model_19.joblib',\n 'gmm_model_20.joblib',\n 'gmm_model_21.joblib',\n 'gmm_model_22.joblib',\n 'gmm_model_23.joblib',\n 'gmm_model_24.joblib',\n 'gmm_model_25.joblib',\n 'gmm_model_26.joblib',\n 'gmm_model_27.joblib',\n 'gmm_model_28.joblib',\n 'gmm_model_29.joblib']"},"metadata":{}}]},{"cell_type":"code","source":"load_gmm_list={}\nlabel=0\n\nfor model in sorted_model_list:\n    model_path=os.path.join(model_directory,model)\n    load_gmm_list[label] = joblib.load(model_path)\n    label=label+1","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:06:23.058207Z","iopub.execute_input":"2023-11-19T04:06:23.058666Z","iopub.status.idle":"2023-11-19T04:06:23.348072Z","shell.execute_reply.started":"2023-11-19T04:06:23.058627Z","shell.execute_reply":"2023-11-19T04:06:23.347134Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"load_gmm_list","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:06:26.256356Z","iopub.execute_input":"2023-11-19T04:06:26.257398Z","iopub.status.idle":"2023-11-19T04:06:26.287655Z","shell.execute_reply.started":"2023-11-19T04:06:26.257353Z","shell.execute_reply":"2023-11-19T04:06:26.286492Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"{0: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 1: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 2: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 3: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 4: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 5: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 6: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 7: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 8: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 9: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 10: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 11: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 12: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 13: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 14: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 15: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 16: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 17: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 18: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 19: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 20: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 21: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 22: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 23: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 24: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 25: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 26: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 27: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 28: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5),\n 29: GaussianMixture(init_params='k-means++', max_iter=150, n_components=10,\n                 reg_covar=0.5)}"},"metadata":{}}]},{"cell_type":"code","source":"likelihoods = {}\n    \nfor class_label, gmm_model in load_gmm_list.items():  # Iterate through your trained GMM models\n    likelihood= gmm_model.score(combined_features)\n        \n    likelihoods[class_label] = likelihood\n    \n    # Predict the label based on the GMM with the highest likelihood score\n    predicted_label = max(likelihoods, key=likelihoods.get)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:06:30.583398Z","iopub.execute_input":"2023-11-19T04:06:30.583834Z","iopub.status.idle":"2023-11-19T04:06:30.625793Z","shell.execute_reply.started":"2023-11-19T04:06:30.583802Z","shell.execute_reply":"2023-11-19T04:06:30.624252Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"print(\"The predicted label for the test data is :\",predicted_label)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T04:06:33.501736Z","iopub.execute_input":"2023-11-19T04:06:33.502143Z","iopub.status.idle":"2023-11-19T04:06:33.509619Z","shell.execute_reply.started":"2023-11-19T04:06:33.502112Z","shell.execute_reply":"2023-11-19T04:06:33.508282Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"The predicted label for the test data is : 1\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}